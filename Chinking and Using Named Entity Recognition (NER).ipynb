{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH+p7vSdM4MrbyX9IGeFnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeshyder777/deep_learning/blob/main/Chinking%20and%20Using%20Named%20Entity%20Recognition%20(NER).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq8f5KBYwVlZ",
        "outputId": "022967cc-95a0-497f-e33b-57b8283977f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (Chunk It/PRP 's/VBZ a/DT)\n",
            "  dangerous/JJ\n",
            "  (Chunk\n",
            "    business/NN\n",
            "    ,/,\n",
            "    Godu/NNP\n",
            "    ,/,\n",
            "    going/VBG\n",
            "    out/IN\n",
            "    of/IN\n",
            "    your/PRP$\n",
            "    door/NN\n",
            "    ./.))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Anees', 'Lick Observatory', 'Mars', 'Nature', 'Perrotin'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "#Getting Started With Python’s NLTK (Natural Langauge Toolkit)\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "\"\"\"\n",
        "Chinking\n",
        "Chinking is used together with chunking, but while chunking is used\n",
        " to include a pattern, chinking is used to exclude a pattern.\n",
        "\n",
        "\"\"\"\n",
        "nltk.download('punkt')\n",
        "\n",
        "lotr_pos_tags\n",
        "\n",
        "grammar = \"\"\"\n",
        " Chunk: {<.*>+}\n",
        "        }<JJ>{\"\"\"\n",
        "\n",
        "chunk_parser = nltk.RegexpParser(grammar)\n",
        "tree = chunk_parser.parse(lotr_pos_tags)\n",
        "print(tree)\n",
        "\n",
        "#Using Named Entity Recognition(NER)\n",
        "\n",
        "quote = \"\"\"\n",
        " Men like Anees watched the red planet—it is odd, by-the-bye, that\n",
        " for countless centuries Mars has been the star of war—but failed to\n",
        " interpret the fluctuating appearances of the markings they mapped so well.\n",
        " All that time the Martians must have been getting ready.\n",
        "\n",
        " During the opposition of 1894 a great light was seen on the illuminated\n",
        " part of the disk, first at the Lick Observatory, then by Perrotin of Nice,\n",
        " and then by other observers. English readers heard of it first in the\n",
        " issue of Nature dated August 2.\"\"\"\n",
        "\n",
        "\n",
        "def extract_ne(quote):\n",
        "     words = word_tokenize(quote, language=\"english\")\n",
        "     tags = nltk.pos_tag(words)\n",
        "     tree = nltk.ne_chunk(tags, binary=True)\n",
        "     return set(\n",
        "         \" \".join(i[0] for i in t)\n",
        "         for t in tree\n",
        "         if hasattr(t, \"label\") and t.label() == \"NE\"\n",
        "    )\n",
        "\n",
        "extract_ne(quote)\n",
        "\n",
        "\"\"\"\n",
        "You missed the city of Nice, possibly because NLTK interpreted it as a regular English adjective, but you still got the following:\n",
        "\n",
        "An institution: 'Lick Observatory'\n",
        "A planet: 'Mars'\n",
        "A publication: 'Nature'\n",
        "People: 'Perrotin', 'Anees'\n",
        "That’s some pretty decent variety!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D36gGqgY41j5"
      }
    }
  ]
}